{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946a4ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\project\\Plant_diseases_Clf\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c64fdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b5693",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),            # Resize the image to 256x256 pixels\n",
    "    transforms.CenterCrop(224),        # Crop the center 224x224 portion\n",
    "    transforms.ToTensor(),             # Convert to tensor (0-1 range)\n",
    "    transforms.Normalize(              # Normalize with ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=datasets.ImageFolder(root=dir,transform=transform)\n",
    "val_ds=datasets.ImageFolder(root=dir,transform=transform)\n",
    "train_loader=DataLoader(train_ds,batch_size=32,shuffle=True)\n",
    "val_loader=DataLoader(val_ds,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffbddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc=nn.Linear(in_features=512,out_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "epouqe=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epouqe):\n",
    "  model.train()\n",
    "  total_loss=0\n",
    "  for batch in tqdm(train_loader,total=len(train_loader)):\n",
    "    imgs , labels = batch\n",
    "    imgs=imgs\n",
    "    labels=labels\n",
    "    optimizer.zero_grad()\n",
    "    outs=model(imgs)\n",
    "    loss_val=loss_fn(outs,labels)\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "    total_loss+=loss_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d07500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
